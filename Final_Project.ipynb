{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f9fee3b-b309-4882-af9f-fc686f6bb348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting wget\n  Downloading wget-3.2.zip (10 kB)\nBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py): started\n  Building wheel for wget (setup.py): finished with status 'done'\n  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=a3244a34fe0e8a834894fbfee26e845eeb8789cfa022681cc464c29c17968ab1\n  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\nSuccessfully built wget\nInstalling collected packages: wget\nSuccessfully installed wget-3.2\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "# Install wget\n",
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac3d3d63-bcbf-42c8-96bc-f8c3763cc124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/degrees/</td><td>degrees/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/name.basics.tsv.gz</td><td>name.basics.tsv.gz</td><td>282889413</td><td>1744299075000</td></tr><tr><td>dbfs:/FileStore/tables/</td><td>tables/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/title.akas.tsv.gz</td><td>title.akas.tsv.gz</td><td>450103193</td><td>1744299104000</td></tr><tr><td>dbfs:/FileStore/title.basics.tsv.gz</td><td>title.basics.tsv.gz</td><td>204295954</td><td>1744299121000</td></tr><tr><td>dbfs:/FileStore/title.crew.tsv.gz</td><td>title.crew.tsv.gz</td><td>75652116</td><td>1744299127000</td></tr><tr><td>dbfs:/FileStore/title.episode.tsv.gz</td><td>title.episode.tsv.gz</td><td>49112241</td><td>1744299131000</td></tr><tr><td>dbfs:/FileStore/title.principals.tsv.gz</td><td>title.principals.tsv.gz</td><td>711208252</td><td>1744299174000</td></tr><tr><td>dbfs:/FileStore/title.ratings.tsv.gz</td><td>title.ratings.tsv.gz</td><td>7830233</td><td>1744299181000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/degrees/",
         "degrees/",
         0,
         0
        ],
        [
         "dbfs:/FileStore/name.basics.tsv.gz",
         "name.basics.tsv.gz",
         282889413,
         1744299075000
        ],
        [
         "dbfs:/FileStore/tables/",
         "tables/",
         0,
         0
        ],
        [
         "dbfs:/FileStore/title.akas.tsv.gz",
         "title.akas.tsv.gz",
         450103193,
         1744299104000
        ],
        [
         "dbfs:/FileStore/title.basics.tsv.gz",
         "title.basics.tsv.gz",
         204295954,
         1744299121000
        ],
        [
         "dbfs:/FileStore/title.crew.tsv.gz",
         "title.crew.tsv.gz",
         75652116,
         1744299127000
        ],
        [
         "dbfs:/FileStore/title.episode.tsv.gz",
         "title.episode.tsv.gz",
         49112241,
         1744299131000
        ],
        [
         "dbfs:/FileStore/title.principals.tsv.gz",
         "title.principals.tsv.gz",
         711208252,
         1744299174000
        ],
        [
         "dbfs:/FileStore/title.ratings.tsv.gz",
         "title.ratings.tsv.gz",
         7830233,
         1744299181000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load The Data\n",
    "import wget\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "# Define the URLs for the IMDb datasets\n",
    "name_basics_url = \"https://datasets.imdbws.com/name.basics.tsv.gz\"\n",
    "title_akas_url = \"https://datasets.imdbws.com/title.akas.tsv.gz\"\n",
    "title_basics_url = \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "title_crew_url = \"https://datasets.imdbws.com/title.crew.tsv.gz\"\n",
    "title_episode_url = \"https://datasets.imdbws.com/title.episode.tsv.gz\"\n",
    "title_principals_url = \"https://datasets.imdbws.com/title.principals.tsv.gz\"\n",
    "title_ratings_url = \"https://datasets.imdbws.com/title.ratings.tsv.gz\"\n",
    "\n",
    "# List of dataset URLs\n",
    "data_set_urls = [\n",
    "    name_basics_url,\n",
    "    title_akas_url,\n",
    "    title_basics_url,\n",
    "    title_crew_url,\n",
    "    title_episode_url,\n",
    "    title_principals_url,\n",
    "    title_ratings_url\n",
    "]\n",
    "\n",
    "# Download and copy datasets to DBFS\n",
    "for url in data_set_urls: \n",
    "    # Get the file name from the URL\n",
    "    f_start = url.rfind(\"/\") \n",
    "    f_name = url[(f_start + 1):]\n",
    "    \n",
    "    # Download the dataset\n",
    "    tsv_path = wget.download(url, f_name)\n",
    "    \n",
    "    # Copy to DBFS\n",
    "    dbutils.fs.cp(f\"file:/databricks/driver/{f_name}\", f\"dbfs:/FileStore/{f_name}\")\n",
    "\n",
    "# Display the files in the FileStore directory\n",
    "display(dbutils.fs.ls('dbfs:/FileStore/'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fb8a21f-a9f9-4510-93d8-b8bf3f0ca18e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**1. Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f3a700-64ec-461a-b42b-3afd2634062f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Base path\n",
    "base_path = \"/FileStore/\"\n",
    "\n",
    "# Load GZ-compressed TSV files directly\n",
    "name_basics_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"name.basics.tsv.gz\")\n",
    "title_akas_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"title.akas.tsv.gz\")\n",
    "title_basics_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"title.basics.tsv.gz\")\n",
    "title_crew_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"title.crew.tsv.gz\")\n",
    "title_episode_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"title.episode.tsv.gz\")\n",
    "title_principals_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"title.principals.tsv.gz\")\n",
    "title_ratings_df = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").option(\"nullValue\", \"\\\\N\").csv(base_path + \"title.ratings.tsv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ada33ae-212c-4c90-8df5-268ac35bcea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n== Schema for title_basics_df ==\nroot\n |-- tconst: string (nullable = true)\n |-- titleType: string (nullable = true)\n |-- primaryTitle: string (nullable = true)\n |-- originalTitle: string (nullable = true)\n |-- isAdult: string (nullable = true)\n |-- startYear: string (nullable = true)\n |-- endYear: string (nullable = true)\n |-- runtimeMinutes: string (nullable = true)\n |-- genres: string (nullable = true)\n\n\n== Preview of title_basics_df ==\n+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|\n+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|   null|             1|   Documentary,Short|\n|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|   null|             5|     Animation,Short|\n|tt0000003|    short|        Poor Pierrot|      Pauvre Pierrot|      0|     1892|   null|             5|Animation,Comedy,...|\n|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|   null|            12|     Animation,Short|\n|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|   null|             1|               Short|\n+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\nonly showing top 5 rows\n\n\n== Schema for title_ratings_df ==\nroot\n |-- tconst: string (nullable = true)\n |-- averageRating: string (nullable = true)\n |-- numVotes: string (nullable = true)\n\n\n== Preview of title_ratings_df ==\n+---------+-------------+--------+\n|   tconst|averageRating|numVotes|\n+---------+-------------+--------+\n|tt0000001|          5.7|    2148|\n|tt0000002|          5.5|     292|\n|tt0000003|          6.5|    2182|\n|tt0000004|          5.3|     188|\n|tt0000005|          6.2|    2925|\n+---------+-------------+--------+\nonly showing top 5 rows\n\n\n== Schema for title_crew_df ==\nroot\n |-- tconst: string (nullable = true)\n |-- directors: string (nullable = true)\n |-- writers: string (nullable = true)\n\n\n== Preview of title_crew_df ==\n+---------+---------+---------+\n|   tconst|directors|  writers|\n+---------+---------+---------+\n|tt0000001|nm0005690|     null|\n|tt0000002|nm0721526|     null|\n|tt0000003|nm0721526|nm0721526|\n|tt0000004|nm0721526|     null|\n|tt0000005|nm0005690|     null|\n+---------+---------+---------+\nonly showing top 5 rows\n\n\n== Schema for title_principals_df ==\nroot\n |-- tconst: string (nullable = true)\n |-- ordering: string (nullable = true)\n |-- nconst: string (nullable = true)\n |-- category: string (nullable = true)\n |-- job: string (nullable = true)\n |-- characters: string (nullable = true)\n\n\n== Preview of title_principals_df ==\n+---------+--------+---------+---------------+--------------------+----------+\n|   tconst|ordering|   nconst|       category|                 job|characters|\n+---------+--------+---------+---------------+--------------------+----------+\n|tt0000001|       1|nm1588970|           self|                null|  [\"Self\"]|\n|tt0000001|       2|nm0005690|       director|                null|      null|\n|tt0000001|       3|nm0005690|       producer|            producer|      null|\n|tt0000001|       4|nm0374658|cinematographer|director of photo...|      null|\n|tt0000002|       1|nm0721526|       director|                null|      null|\n+---------+--------+---------+---------------+--------------------+----------+\nonly showing top 5 rows\n\n\n== Schema for title_episode_df ==\nroot\n |-- tconst: string (nullable = true)\n |-- parentTconst: string (nullable = true)\n |-- seasonNumber: string (nullable = true)\n |-- episodeNumber: string (nullable = true)\n\n\n== Preview of title_episode_df ==\n+---------+------------+------------+-------------+\n|   tconst|parentTconst|seasonNumber|episodeNumber|\n+---------+------------+------------+-------------+\n|tt0031458|  tt32857063|        null|         null|\n|tt0041951|   tt0041038|           1|            9|\n|tt0042816|   tt0989125|           1|           17|\n|tt0042889|   tt0989125|        null|         null|\n|tt0043426|   tt0040051|           3|           42|\n+---------+------------+------------+-------------+\nonly showing top 5 rows\n\n\n== Schema for title_akas_df ==\nroot\n |-- titleId: string (nullable = true)\n |-- ordering: string (nullable = true)\n |-- title: string (nullable = true)\n |-- region: string (nullable = true)\n |-- language: string (nullable = true)\n |-- types: string (nullable = true)\n |-- attributes: string (nullable = true)\n |-- isOriginalTitle: string (nullable = true)\n\n\n== Preview of title_akas_df ==\n+---------+--------+--------------------+------+--------+-----------+-------------+---------------+\n|  titleId|ordering|               title|region|language|      types|   attributes|isOriginalTitle|\n+---------+--------+--------------------+------+--------+-----------+-------------+---------------+\n|tt0000001|       1|          Carmencita|  null|    null|   original|         null|              1|\n|tt0000001|       2|          Carmencita|    DE|    null|       null|literal title|              0|\n|tt0000001|       3|          Carmencita|    US|    null|imdbDisplay|         null|              0|\n|tt0000001|       4|Carmencita - span...|    HU|    null|imdbDisplay|         null|              0|\n|tt0000001|       5|          Καρμενσίτα|    GR|    null|imdbDisplay|         null|              0|\n+---------+--------+--------------------+------+--------+-----------+-------------+---------------+\nonly showing top 5 rows\n\n\n== Schema for name_basics_df ==\nroot\n |-- nconst: string (nullable = true)\n |-- primaryName: string (nullable = true)\n |-- birthYear: string (nullable = true)\n |-- deathYear: string (nullable = true)\n |-- primaryProfession: string (nullable = true)\n |-- knownForTitles: string (nullable = true)\n\n\n== Preview of name_basics_df ==\n+---------+---------------+---------+---------+--------------------+--------------------+\n|   nconst|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n+---------+---------------+---------+---------+--------------------+--------------------+\n|nm0000001|   Fred Astaire|     1899|     1987|actor,miscellaneo...|tt0072308,tt00504...|\n|nm0000002|  Lauren Bacall|     1924|     2014|actress,soundtrac...|tt0037382,tt00752...|\n|nm0000003|Brigitte Bardot|     1934|     null|actress,music_dep...|tt0057345,tt00491...|\n|nm0000004|   John Belushi|     1949|     1982|actor,writer,musi...|tt0072562,tt00779...|\n|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00694...|\n+---------+---------------+---------+---------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "dfs = {\n",
    "    \"title_basics_df\": title_basics_df,\n",
    "    \"title_ratings_df\": title_ratings_df,\n",
    "    \"title_crew_df\": title_crew_df,\n",
    "    \"title_principals_df\": title_principals_df,\n",
    "    \"title_episode_df\": title_episode_df,\n",
    "    \"title_akas_df\": title_akas_df,\n",
    "    \"name_basics_df\": name_basics_df\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n== Schema for {name} ==\")\n",
    "    df.printSchema()\n",
    "    print(f\"\\n== Preview of {name} ==\")\n",
    "    df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adfb9c66-647e-4472-a88f-25e96b10f361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2. How many total people in data set**\n",
    "- Total number of people in the IMDb dataset: 14325453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab36f9ae-6618-4b97-be01-531abc487fd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people in the IMDb dataset: 14325453\n"
     ]
    }
   ],
   "source": [
    "total_people = name_basics_df.count()\n",
    "print(f\"Total number of people in the IMDb dataset: {total_people}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bc439a8-4729-49a2-ad60-bb59a066b04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct people (nconst): 14325453\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "distinct_people = name_basics_df.select(\"nconst\").distinct().count()\n",
    "print(f\"Total distinct people (nconst): {distinct_people}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9178c3b-f8a3-405a-a641-c30f92602a60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3. What is the earliest year of birth**\n",
    "- Lucio Anneo Seneca| 4        |writer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94bf8e81-3e23-44f8-9932-39402b02532c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest recorded birth year is: 4\n+------------------+---------+-----------------+\n|primaryName       |birthYear|primaryProfession|\n+------------------+---------+-----------------+\n|Lucio Anneo Seneca|4        |writer           |\n+------------------+---------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Cast 'birthYear' to Integer\n",
    "name_basics_df = name_basics_df.withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "\n",
    "# Step 2: Find the earliest (unfiltered) birth year\n",
    "earliest_birth = name_basics_df \\\n",
    "    .filter(col(\"birthYear\").isNotNull()) \\\n",
    "    .orderBy(\"birthYear\") \\\n",
    "    .select(\"birthYear\") \\\n",
    "    .first()[\"birthYear\"]\n",
    "\n",
    "print(f\"The earliest recorded birth year is: {earliest_birth}\")\n",
    "\n",
    "# Step 3: Show the person(s) born in that year\n",
    "name_basics_df \\\n",
    "    .filter(col(\"birthYear\") == earliest_birth) \\\n",
    "    .select(\"primaryName\", \"birthYear\", \"primaryProfession\") \\\n",
    "    .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9db73f8-8a0c-445f-9041-295693bcc4bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**4. How many years ago was this person born**\n",
    "- Lucio Anneo Seneca was born 2021 years ago.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce39a8ce-9496-4957-8ece-00b3304c194a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucio Anneo Seneca was born 2021 years ago.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Use previously found earliest_birth value (which was 4)\n",
    "years_ago = current_year - earliest_birth\n",
    "\n",
    "print(f\"Lucio Anneo Seneca was born {years_ago} years ago.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2a494dc-648c-41a4-b683-918a75de4191",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**5. Using only the data in the data set is this date of birth correct . explain the answer**\n",
    "- Yes, based only on the IMDb dataset, the date of birth (year 4) is considered valid.\n",
    "There's no conflict in the data: both birth and death years are present, and IMDb includes historical figures when they’re credited in titles. The dataset does not verify historical accuracy — it only reflects credits from the entertainment industry.\n",
    "Yes, based only on the IMDb dataset, the date of birth (year 4) is considered valid. There's no conflict in the data: both birth and death years are present, and IMDb includes historical figures when they’re credited in titles. The dataset does not verify historical accuracy — it only reflects credits from the entertainment industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7466907b-2ea0-44c6-a1a2-4d34226a1f3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+---------+---------+-----------------+---------------------------------------+\n|nconst   |primaryName       |birthYear|deathYear|primaryProfession|knownForTitles                         |\n+---------+------------------+---------+---------+-----------------+---------------------------------------+\n|nm0784172|Lucio Anneo Seneca|4        |65       |writer           |tt0043802,tt0218822,tt0049203,tt0972562|\n+---------+------------------+---------+---------+-----------------+---------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find Seneca by name (case-insensitive contains)\n",
    "seneca_df = name_basics_df.filter(col(\"primaryName\").like(\"%Lucio Anneo Seneca%\"))\n",
    "\n",
    "seneca_df.select(\"nconst\", \"primaryName\", \"birthYear\", \"deathYear\", \"primaryProfession\", \"knownForTitles\") \\\n",
    "         .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "561564cf-b6d5-45d1-becb-49512b6ffb48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**6. What is the latest data of birth**\n",
    "- The most recent recorded birth year is: 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25a84682-0693-4866-8593-6a8745067596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent recorded birth year is: 2024\n+--------------------+---------+-------------------------------+\n|primaryName         |birthYear|primaryProfession              |\n+--------------------+---------+-------------------------------+\n|Ronnie Lordi        |2024     |actor,writer,producer          |\n|Aris A. Stavropoulos|2024     |producer                       |\n|Christina Goitia    |2024     |actress                        |\n|Turner Samuel       |2024     |null                           |\n|Moo Deng            |2024     |archive_footage                |\n|Alexandra Ardelyan  |2024     |writer,editor,director         |\n|Jerzy Ficowski      |2024     |writer,miscellaneous,soundtrack|\n+--------------------+---------+-------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Cast 'birthYear' to Integer\n",
    "name_basics_df = name_basics_df.withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "\n",
    "# Step 2: Find the latest (unfiltered) birth year\n",
    "latest_birth = name_basics_df \\\n",
    "    .filter(col(\"birthYear\").isNotNull()) \\\n",
    "    .orderBy(col(\"birthYear\").desc()) \\\n",
    "    .select(\"birthYear\") \\\n",
    "    .first()[\"birthYear\"]\n",
    "\n",
    "print(f\"The most recent recorded birth year is: {latest_birth}\")\n",
    "\n",
    "# Step 3: Show the person(s) born in that year\n",
    "name_basics_df \\\n",
    "    .filter(col(\"birthYear\") == latest_birth) \\\n",
    "    .select(\"primaryName\", \"birthYear\", \"primaryProfession\") \\\n",
    "    .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "297bbaf3-42da-40ad-acdc-ac3680addd84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**7. How many people do not have a year of birth**\n",
    "- Number of people without a recorded birth year: 13682359\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fda6c2-673b-4901-aba3-be1da33f2e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people without a recorded birth year: 13682359\n"
     ]
    }
   ],
   "source": [
    "# Ensure birthYear is cast to integer\n",
    "name_basics_df = name_basics_df.withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "\n",
    "# Count people where birthYear is null\n",
    "missing_birth_year_count = name_basics_df.filter(col(\"birthYear\").isNull()).count()\n",
    "\n",
    "print(f\"Number of people without a recorded birth year: {missing_birth_year_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11eb5ea8-bf77-4fe7-8d0f-d18d1f92ef21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**8. What is the length of the longest short after 1900**\n",
    "- The longest short film after 1900 is 'Tanha Dar Mazrae' (2024) with a runtime of 250 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bccdb375-7ca8-427f-915c-125d9b1525d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest short film after 1900 is 'Tanha Dar Mazrae' (2024) with a runtime of 250 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct data types\n",
    "title_basics_df = title_basics_df.withColumn(\"startYear\", col(\"startYear\").cast(\"int\")) \\\n",
    "                                 .withColumn(\"runtimeMinutes\", col(\"runtimeMinutes\").cast(\"int\"))\n",
    "\n",
    "# Filter for short films after 1900 with valid runtime\n",
    "longest_short_df = title_basics_df.filter(\n",
    "    (col(\"titleType\") == \"short\") &\n",
    "    (col(\"startYear\") > 1900) &\n",
    "    (col(\"runtimeMinutes\").isNotNull())\n",
    ")\n",
    "\n",
    "# Get the longest short film\n",
    "longest_short = longest_short_df.orderBy(col(\"runtimeMinutes\").desc()).select(\n",
    "    \"primaryTitle\", \"startYear\", \"runtimeMinutes\"\n",
    ").first()\n",
    "\n",
    "# Show result\n",
    "print(f\"The longest short film after 1900 is '{longest_short['primaryTitle']}' \"\n",
    "      f\"({longest_short['startYear']}) with a runtime of {longest_short['runtimeMinutes']} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b598a6c5-14e9-4939-a55b-3b3353b4bc25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8b68eb-be54-45a2-897f-1211b2b0bfac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "title_basics_df.createOrReplaceTempView(\"title_basics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2321b1ed-e67e-4e51-aab3-15ab76e08ef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>primaryTitle</th><th>startYear</th><th>runtimeMinutes</th></tr></thead><tbody><tr><td>Tanha Dar Mazrae</td><td>2024</td><td>250</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Tanha Dar Mazrae",
         2024,
         250
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "primaryTitle",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "startYear",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "runtimeMinutes",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Filter for short films after 1900 with valid runtime\n",
    "WITH longest_short AS (\n",
    "    SELECT primaryTitle, startYear, runtimeMinutes\n",
    "    FROM title_basics\n",
    "    WHERE titleType = 'short'\n",
    "      AND startYear > 1900\n",
    "      AND runtimeMinutes IS NOT NULL\n",
    ")\n",
    "-- Get the longest short film\n",
    "SELECT primaryTitle, startYear, runtimeMinutes\n",
    "FROM longest_short\n",
    "ORDER BY runtimeMinutes DESC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e072a43-e08c-4aae-86c8-ecba96bde452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**9. What is the length of the shortest movie after 1900**\n",
    "- The shortest movie after 1900 is 'George White's Scandals' (1934) with a runtime of 1 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12796057-7f62-412f-948f-6bb5855d3962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest movie after 1900 is 'George White's Scandals' (1934) with a runtime of 1 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct data types\n",
    "title_basics_df = title_basics_df.withColumn(\"startYear\", col(\"startYear\").cast(\"int\")) \\\n",
    "                                 .withColumn(\"runtimeMinutes\", col(\"runtimeMinutes\").cast(\"int\"))\n",
    "\n",
    "# Filter for full-length movies after 1900 with valid runtime\n",
    "shortest_movie_df = title_basics_df.filter(\n",
    "    (col(\"titleType\") == \"movie\") &\n",
    "    (col(\"startYear\") > 1900) &\n",
    "    (col(\"runtimeMinutes\").isNotNull()) &\n",
    "    (col(\"runtimeMinutes\") > 0)  # avoid weird zero-minute entries\n",
    ")\n",
    "\n",
    "# Get the shortest movie\n",
    "shortest_movie = shortest_movie_df.orderBy(col(\"runtimeMinutes\").asc()).select(\n",
    "    \"primaryTitle\", \"startYear\", \"runtimeMinutes\"\n",
    ").first()\n",
    "\n",
    "# Show result\n",
    "print(f\"The shortest movie after 1900 is '{shortest_movie['primaryTitle']}' \"\n",
    "      f\"({shortest_movie['startYear']}) with a runtime of {shortest_movie['runtimeMinutes']} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17b00ef9-cab7-4080-91a1-7c3c73771806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25cd554b-439e-4355-a01e-8f382baf7378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "title_basics_df.createOrReplaceTempView(\"title_basics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2afecceb-1388-4af5-a10b-6a6beba2a005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>primaryTitle</th><th>startYear</th><th>runtimeMinutes</th></tr></thead><tbody><tr><td>George White's Scandals</td><td>1934</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "George White's Scandals",
         1934,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "primaryTitle",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "startYear",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "runtimeMinutes",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Filter for full-length movies after 1900 with valid runtime\n",
    "WITH shortest_movie AS (\n",
    "    SELECT primaryTitle, startYear, runtimeMinutes\n",
    "    FROM title_basics\n",
    "    WHERE titleType = 'movie'\n",
    "      AND startYear > 1900\n",
    "      AND runtimeMinutes IS NOT NULL\n",
    "      AND runtimeMinutes > 0  -- Avoid zero-minute entries\n",
    ")\n",
    "-- Get the shortest movie\n",
    "SELECT primaryTitle, startYear, runtimeMinutes\n",
    "FROM shortest_movie\n",
    "ORDER BY runtimeMinutes ASC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81043de9-f6f4-45b1-864c-598046940fe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**10. Provide a list of all of the genres represented**\n",
    "- |Action|Adult|Adventure  |Animation|Biography|Comedy|Crime|Documentary|Drama|Family|Fantasy|Film-Noir|Game-Show|History|Horror|Music|Musical|Mystery|News|Reality-TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92730c7c-2d2c-4833-876f-f97684494a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|genre      |\n+-----------+\n|Action     |\n|Adult      |\n|Adventure  |\n|Animation  |\n|Biography  |\n|Comedy     |\n|Crime      |\n|Documentary|\n|Drama      |\n|Family     |\n|Fantasy    |\n|Film-Noir  |\n|Game-Show  |\n|History    |\n|Horror     |\n|Music      |\n|Musical    |\n|Mystery    |\n|News       |\n|Reality-TV |\n+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "# Filter nulls and split genre strings into arrays\n",
    "genres_df = title_basics_df \\\n",
    "    .filter(col(\"genres\").isNotNull()) \\\n",
    "    .withColumn(\"genre\", explode(split(col(\"genres\"), \",\")))\n",
    "\n",
    "# Get distinct genres\n",
    "unique_genres = genres_df.select(\"genre\").distinct().orderBy(\"genre\")\n",
    "\n",
    "# Show all genres\n",
    "unique_genres.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb7b0cf0-1bde-47a6-af9f-9b2473ed5a50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**11. What is the higest rated comedy movie in the dataset . note, if there is a tie, the tie shall be broken by the movie with the most votes.**\n",
    "- The highest-rated comedy movie is 'Here They Go' (2022) with a rating of 10.0 based on 8 votes. Genres: Comedy,Family\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c0fa09-bd6f-4d30-a6ce-586454007166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest-rated comedy movie is 'Here They Go' (2022) with a rating of 10.0 based on 8 votes. Genres: Comedy,Family\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct data types\n",
    "title_ratings_df = title_ratings_df.withColumn(\"averageRating\", col(\"averageRating\").cast(\"float\")) \\\n",
    "                                   .withColumn(\"numVotes\", col(\"numVotes\").cast(\"int\"))\n",
    "\n",
    "# Filter movies that include 'Comedy' as one of the genres\n",
    "comedy_movies_df = title_basics_df.filter(\n",
    "    (col(\"titleType\") == \"movie\") &\n",
    "    (col(\"genres\").isNotNull()) &\n",
    "    (col(\"genres\").like(\"%Comedy%\"))\n",
    ")\n",
    "\n",
    "# Join with ratings\n",
    "comedy_with_ratings = comedy_movies_df.join(title_ratings_df, on=\"tconst\", how=\"inner\")\n",
    "\n",
    "# Order by rating, then number of votes\n",
    "top_comedy = comedy_with_ratings.orderBy(\n",
    "    col(\"averageRating\").desc(),\n",
    "    col(\"numVotes\").desc()\n",
    ").select(\"primaryTitle\", \"startYear\", \"averageRating\", \"numVotes\", \"genres\").first()\n",
    "\n",
    "# Show result\n",
    "print(f\"The highest-rated comedy movie is '{top_comedy['primaryTitle']}' \"\n",
    "      f\"({top_comedy['startYear']}) with a rating of {top_comedy['averageRating']} \"\n",
    "      f\"based on {top_comedy['numVotes']} votes. Genres: {top_comedy['genres']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b9c76a4-d405-4b50-aed9-6c71c7feb2ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**12. Who was the director of the movie.**\n",
    "- Bryan Bostic|director,writer,editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e95e1c5-1698-4ff8-b7c9-0b5fa78b5685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+\n|primaryName |primaryProfession     |\n+------------+----------------------+\n|Bryan Bostic|director,writer,editor|\n+------------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get the tconst of the highest-rated comedy movie\n",
    "top_comedy_tconst = comedy_with_ratings.orderBy(\n",
    "    col(\"averageRating\").desc(),\n",
    "    col(\"numVotes\").desc()\n",
    ").select(\"tconst\").first()[\"tconst\"]\n",
    "\n",
    "# Step 2: Get the director nconst(s) from title_crew_df\n",
    "director_ids = title_crew_df.filter(col(\"tconst\") == top_comedy_tconst) \\\n",
    "    .select(\"directors\").first()[\"directors\"]\n",
    "\n",
    "# Step 3: Handle multiple directors (split by comma)\n",
    "director_id_list = director_ids.split(\",\")\n",
    "\n",
    "# Step 4: Get director names from name_basics_df\n",
    "directors_df = name_basics_df.filter(col(\"nconst\").isin(director_id_list)) \\\n",
    "    .select(\"primaryName\", \"primaryProfession\")\n",
    "\n",
    "directors_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "156c5678-7d6e-481b-a03c-5d260edac181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**13. List, if any, the alternate titles for the movie .**\n",
    "- Alternate titles for the movie with tconst = tt20115996:\n",
    "- |Here They Go|null  |null    |original   |null      |1           \n",
    "- |Here They Go|US    |null    |imdbDisplay|null      |0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a98b3e-056a-47e0-9b93-cc1cb3d12cad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternate titles for the movie with tconst = tt20115996:\n\n+------------+------+--------+-----------+----------+---------------+\n|title       |region|language|types      |attributes|isOriginalTitle|\n+------------+------+--------+-----------+----------+---------------+\n|Here They Go|null  |null    |original   |null      |1              |\n|Here They Go|US    |null    |imdbDisplay|null      |0              |\n+------------+------+--------+-----------+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Use the same tconst from earlier (already stored in top_comedy_tconst)\n",
    "\n",
    "# Filter title.akas for that tconst\n",
    "alternate_titles_df = title_akas_df.filter(col(\"titleId\") == top_comedy_tconst)\n",
    "\n",
    "# Check if there are any alternate titles\n",
    "if alternate_titles_df.count() > 1:  # more than one = at least one alternate besides the original\n",
    "    print(f\"Alternate titles for the movie with tconst = {top_comedy_tconst}:\\n\")\n",
    "    alternate_titles_df.select(\"title\", \"region\", \"language\", \"types\", \"attributes\", \"isOriginalTitle\") \\\n",
    "        .show(truncate=False)\n",
    "else:\n",
    "    print(f\"No alternate titles found for the movie with tconst = {top_comedy_tconst}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c84f46f-f400-4397-8843-219848c2ad69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**14. Build the degrees of seperation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261417e1-dfd3-4e79-86f8-76626de5799e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[109]: DataFrame[tconst: string, titleType: string, primaryTitle: string, originalTitle: string, isAdult: string, startYear: int, endYear: string, runtimeMinutes: int, genres: string]"
     ]
    }
   ],
   "source": [
    "name_basics_df.cache()\n",
    "title_principals_df.cache()\n",
    "title_basics_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5e7562-e3eb-4eb7-b088-22bdae3deee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---------+---------+--------------------+--------------------+\n|   nconst|primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n+---------+-----------+---------+---------+--------------------+--------------------+\n|nm0000102|Kevin Bacon|     1958|     null|actor,producer,di...|tt0087277,tt01640...|\n+---------+-----------+---------+---------+--------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "degree_0 = name_basics_df.filter(name_basics_df.nconst == \"nm0000102\")\n",
    "degree_0.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_0\")\n",
    "degree_0.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0cd0813-7583-4d3d-a1c5-c19e91387ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|   nconst|\n+---------+\n|nm1139759|\n|nm0251041|\n|nm5016878|\n|nm1635586|\n|nm0000123|\n|nm1057101|\n|nm0000741|\n|nm0000704|\n|nm5812920|\n|nm3994408|\n|nm0000119|\n|nm0137272|\n|nm3666749|\n|nm1296595|\n|nm0004854|\n|nm0086301|\n|nm1284039|\n|nm0227759|\n|nm5441137|\n|nm0166921|\n+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Get titles featuring nm0000102\n",
    "actor_titles = title_principals_df.filter(title_principals_df.nconst == \"nm0000102\") \\\n",
    "                               .select(\"tconst\").distinct()\n",
    "\n",
    "# Find co-actors in the same titles\n",
    "degree_1 = title_principals_df.join(actor_titles, \"tconst\") \\\n",
    "                           .filter(title_principals_df.nconst != \"nm0000102\") \\\n",
    "                           .select(\"nconst\").distinct()\n",
    "\n",
    "degree_1.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_1\")\n",
    "degree_1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fbc159-173a-475f-8e0d-708db7812e50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|    nconst|\n+----------+\n| nm0005706|\n| nm0020967|\n| nm0811256|\n| nm0085812|\n| nm0522844|\n| nm0213142|\n| nm0732440|\n| nm0068551|\n| nm0420949|\n| nm0110951|\n| nm0936837|\n| nm1297550|\n| nm1219967|\n|nm10647687|\n| nm1706032|\n| nm0652288|\n| nm0165145|\n| nm0574206|\n| nm0560754|\n| nm0385591|\n+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "degree_1 = spark.read.parquet(\"/FileStore/imdb/degree_1\")\n",
    "\n",
    "# Find titles of Degree 1 actors\n",
    "degree_1_titles = title_principals_df.join(degree_1, \"nconst\").select(\"tconst\").distinct()\n",
    "\n",
    "# Find Degree 2 actors\n",
    "degree_2 = title_principals_df.join(degree_1_titles, \"tconst\") \\\n",
    "                           .select(\"nconst\").distinct() \\\n",
    "                           .subtract(degree_1).subtract(spark.createDataFrame([(\"nm0000102\",)], [\"nconst\"]))\n",
    "\n",
    "degree_2.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_2\")\n",
    "degree_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d09b744-dc22-49c1-b6b2-f92ac74ca140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|    nconst|\n+----------+\n| nm6128855|\n| nm1012680|\n|nm11521609|\n|nm12198811|\n|nm11960936|\n| nm0701465|\n| nm2748252|\n| nm2770056|\n|nm11968849|\n|nm11969975|\n| nm0516714|\n| nm1296585|\n| nm1690431|\n| nm0126962|\n|nm11524843|\n| nm4695808|\n| nm1791085|\n|nm11832961|\n| nm0240345|\n|nm10946376|\n+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "degree_2 = spark.read.parquet(\"/FileStore/imdb/degree_2\")\n",
    "\n",
    "degree_2_titles = title_principals_df.join(degree_2, \"nconst\").select(\"tconst\").distinct()\n",
    "\n",
    "degree_3 = title_principals_df.join(degree_2_titles, \"tconst\") \\\n",
    "                           .select(\"nconst\").distinct() \\\n",
    "                           .subtract(degree_2).subtract(degree_1).subtract(spark.createDataFrame([(\"nm0000102\",)], [\"nconst\"]))\n",
    "\n",
    "degree_3.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_3\")\n",
    "degree_3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd852d04-dd5a-40cd-b60f-ffd5624a8cbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|    nconst|\n+----------+\n|nm10379575|\n|nm10393973|\n|nm10406493|\n|nm10418659|\n|nm10420177|\n|nm10425330|\n|nm10473888|\n|nm10485417|\n|nm10511950|\n|nm10519654|\n|nm10526909|\n|nm10556435|\n|nm10569784|\n|nm10577666|\n|nm10592182|\n|nm10647654|\n| nm1066295|\n|nm10683152|\n|nm10695122|\n|nm10703799|\n+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "degree_3 = spark.read.parquet(\"/FileStore/imdb/degree_3\")\n",
    "\n",
    "degree_3_titles = title_principals_df.join(degree_3, \"nconst\").select(\"tconst\").distinct()\n",
    "\n",
    "degree_4 = title_principals_df.join(degree_3_titles, \"tconst\") \\\n",
    "                           .select(\"nconst\").distinct() \\\n",
    "                           .subtract(degree_3).subtract(degree_2).subtract(degree_1).subtract(spark.createDataFrame([(\"nm0000102\",)], [\"nconst\"]))\n",
    "\n",
    "degree_4.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_4\")\n",
    "degree_4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c687efd-6bc4-4653-b6ff-469ef994eca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|   nconst|\n+---------+\n|nm0007376|\n|nm0041906|\n|nm0076839|\n|nm0105401|\n|nm0078364|\n|nm0068274|\n|nm0101690|\n|nm0029547|\n|nm0089739|\n|nm0070150|\n|nm0045562|\n|nm0071535|\n|nm0072291|\n|nm0094111|\n|nm0056673|\n|nm0024304|\n|nm0121462|\n|nm0069436|\n|nm0097740|\n|nm0120748|\n+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "degree_1 = spark.read.parquet(\"/FileStore/imdb/degree_1\")\n",
    "degree_2 = spark.read.parquet(\"/FileStore/imdb/degree_2\")\n",
    "degree_3 = spark.read.parquet(\"/FileStore/imdb/degree_3\")\n",
    "degree_4 = spark.read.parquet(\"/FileStore/imdb/degree_4\")\n",
    "\n",
    "degree_4_titles = title_principals_df.join(degree_4, \"nconst\").select(\"tconst\").distinct()\n",
    "\n",
    "degree_5 = title_principals_df.join(degree_4_titles, \"tconst\") \\\n",
    "                           .select(\"nconst\").distinct() \\\n",
    "                           .subtract(degree_4).subtract(degree_3).subtract(degree_2).subtract(degree_1).subtract(spark.createDataFrame([(\"nm0000102\",)], [\"nconst\"]))\n",
    "\n",
    "degree_5.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_5\")\n",
    "degree_5.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f6f1a4-aae4-4247-96ba-ea846d8d106c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|    nconst|\n+----------+\n| nm0046221|\n| nm0729441|\n|nm10034173|\n|nm10036721|\n|nm10109309|\n| nm0326818|\n| nm0602752|\n| nm0208166|\n|nm10036713|\n|nm10119873|\n| nm0865695|\n|nm10029633|\n| nm0375367|\n|nm10102709|\n|nm10039383|\n| nm0275066|\n|nm10125415|\n| nm0867061|\n|nm10050922|\n|nm10045212|\n+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "degree_5 = spark.read.parquet(\"/FileStore/imdb/degree_5\")\n",
    "\n",
    "degree_5_titles = title_principals_df.join(degree_5, \"nconst\").select(\"tconst\").distinct()\n",
    "\n",
    "degree_6 = title_principals_df.join(degree_5_titles, \"tconst\") \\\n",
    "                           .select(\"nconst\").distinct() \\\n",
    "                           .subtract(degree_5).subtract(degree_4).subtract(degree_3).subtract(degree_2).subtract(degree_1).subtract(spark.createDataFrame([(\"nm0000102\",)], [\"nconst\"]))\n",
    "\n",
    "degree_6.write.mode(\"overwrite\").parquet(\"/FileStore/imdb/degree_6\")\n",
    "degree_6.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aceb9ed5-9131-4328-80f2-9d6dae5582d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**15. Which degree of seperation contains the most people**\n",
    "- DEGREE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc3da38-9e21-48b2-9b10-08d53f66fd51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n|  Degree|  Count|\n+--------+-------+\n|Degree 0|      1|\n|Degree 1|   4769|\n|Degree 2| 723186|\n|Degree 3|3902063|\n|Degree 4|1587019|\n|Degree 5| 159851|\n|Degree 6|  16758|\n+--------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "degrees = []\n",
    "for i in range(7):\n",
    "    df = spark.read.parquet(f\"/FileStore/imdb/degree_{i}\")\n",
    "    count = df.count()\n",
    "    degrees.append((f\"Degree {i}\", count))\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "degree_counts_df = spark.createDataFrame(degrees, [\"Degree\", \"Count\"])\n",
    "degree_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f92f896-d5ed-48cb-abd0-bfe49ea0f762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n|degree|  count|\n+------+-------+\n|     3|3902063|\n|     4|1587019|\n|     2| 723186|\n|     5| 159851|\n|     6|  16758|\n|     1|   4769|\n|     0|      1|\n+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from functools import reduce\n",
    "\n",
    "degree_dfs = []\n",
    "\n",
    "for i in range(7):\n",
    "    path = f\"/FileStore/imdb/degree_{i}\"\n",
    "    try:\n",
    "        df = spark.read.parquet(path)\n",
    "        # Ensure only nconst is kept before adding degree column\n",
    "        df = df.select(\"nconst\").withColumn(\"degree\", lit(i))\n",
    "        degree_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping degree_{i}: {e}\")\n",
    "\n",
    "if degree_dfs:\n",
    "    all_degrees_df = reduce(lambda df1, df2: df1.union(df2), degree_dfs)\n",
    "    all_degrees_df.groupBy(\"degree\").count().orderBy(\"count\", ascending=False).show()\n",
    "else:\n",
    "    print(\"No degree data was available for analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7611c8c9-fd72-4c95-b292-d62f49c9d832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**16. Aside from Degree 0, which Degree containes the most people**\n",
    "- DEGREE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f6ebd2-eced-4827-b55f-cb5a43a950bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n|degree|  count|\n+------+-------+\n|     3|3902063|\n+------+-------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "# Group by degree and count the number of people, excluding Degree 0\n",
    "degree_counts = all_degrees_df.filter(all_degrees_df.degree != 0) \\\n",
    "    .groupBy(\"degree\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "\n",
    "degree_counts.show(1)  # Display the degree with the most people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7de397ac-ef31-4c4d-996d-a0842685d04c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**17. Which contains the least**\n",
    "- DEGREE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "470c4d7c-2d49-44e2-b5b8-22b2e836ad46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|degree|count|\n+------+-----+\n|     1| 4769|\n+------+-----+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "# Group by degree and count the number of people, excluding Degree 0\n",
    "degree_counts_least = all_degrees_df.filter(all_degrees_df.degree != 0) \\\n",
    "    .groupBy(\"degree\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=True)\n",
    "\n",
    "degree_counts_least.show(1)  # Display the degree with the least people\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47c50f3a-8ec3-4f1e-9d56-84ff36f46869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**18. Is the person from question 3 within 6 Degrees of nm0000102, if so, how many ?**\n",
    "- The earliest year of birth is: 4\n",
    "- The nconst of this person is: nm0784172\n",
    "- The person from question 3 (nconst: nm0784172) is within 3 degrees of nm0000102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eefb5f2-61f8-42f4-a47a-bb348402527d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest year of birth is: 4\nThe nconst of this person is: nm0784172\n"
     ]
    }
   ],
   "source": [
    "# Filter out null birth years and cast to int\n",
    "earliest_birth_year_df = name_basics_df \\\n",
    "    .filter(col(\"birthYear\").isNotNull()) \\\n",
    "    .withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "\n",
    "# Find the earliest birth year\n",
    "earliest_birth_year = earliest_birth_year_df.agg({\"birthYear\": \"min\"}).collect()[0][0]\n",
    "\n",
    "# Find the nconst for the earliest birth year\n",
    "earliest_person = earliest_birth_year_df \\\n",
    "    .filter(col(\"birthYear\") == earliest_birth_year) \\\n",
    "    .select(\"nconst\") \\\n",
    "    .collect()[0][0]\n",
    "\n",
    "print(f\"The earliest year of birth is: {earliest_birth_year}\")\n",
    "print(f\"The nconst of this person is: {earliest_person}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3853a16e-fabe-4950-b242-c4ecca7c2d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person from question 3 (nconst: nm0784172) is within 3 degrees of nm0000102.\n"
     ]
    }
   ],
   "source": [
    "# Is the person from question 3 within 6 Degrees of nm0000102, if so, how many ?\n",
    "found = False\n",
    "for i in range(1, 7):\n",
    "    degree_df = spark.read.parquet(f\"/FileStore/imdb/degree_{i}\")\n",
    "    if degree_df.filter(degree_df.nconst == earliest_person).count() > 0:\n",
    "        print(f\"The person from question 3 (nconst: {earliest_person}) is within {i} degrees of nm0000102.\")\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(f\"The person from question 3 (nconst: {earliest_person}) is NOT within 6 degrees of nm0000102.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e744da93-b708-4772-b929-16c4814d99df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**19. Is nm0000102 within 6 degrees of the movie from question 11, if so, how many ?**\n",
    "-     The tconst of the highest rated comedy movie is: tt10867894\n",
    "-     Kevin Bacon (nm0000102) is within 2 degrees of the top-rated comedy movie (tconst: tt10867894)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be2cc9f-bc3c-4901-97fa-0b21cd0e7c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tconst of the highest rated comedy movie is: tt10867894\n"
     ]
    }
   ],
   "source": [
    "# Join comedy movies with ratings (explicit join keys)\n",
    "comedy_with_ratings = comedy_movies.join(\n",
    "    title_ratings_df, \n",
    "    comedy_movies[\"tconst_basics\"] == title_ratings_df[\"tconst\"], \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Order by averageRating and numVotes\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "top_comedy_movie_tconst = comedy_with_ratings.orderBy(\n",
    "    col(\"averageRating\").desc(), \n",
    "    col(\"numVotes\").desc()\n",
    ").select(\"tconst\").limit(1).collect()[0][0]\n",
    "\n",
    "print(f\"The tconst of the highest rated comedy movie is: {top_comedy_movie_tconst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73694e09-f0b0-41b7-bfd9-ac02315bb687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kevin Bacon (nm0000102) is within 2 degrees of the top-rated comedy movie (tconst: tt10867894)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Load actors of the top comedy movie\n",
    "comedy_movie_actors_df = title_principals_df.filter(col(\"tconst\") == top_comedy_movie_tconst).select(\"nconst\").distinct()\n",
    "comedy_movie_actors = [row[\"nconst\"] for row in comedy_movie_actors_df.collect()]\n",
    "\n",
    "found = False\n",
    "for degree in range(1, 7):\n",
    "    try:\n",
    "        degree_df = spark.read.parquet(f\"/FileStore/imdb/degree_{degree}\")\n",
    "        match_df = degree_df.filter(col(\"nconst\").isin(comedy_movie_actors))\n",
    "        if match_df.count() > 0:\n",
    "            print(f\" Kevin Bacon (nm0000102) is within {degree} degrees of the top-rated comedy movie (tconst: {top_comedy_movie_tconst})\")\n",
    "            found = True\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\" Could not read degree_{degree}: {e}\")\n",
    "\n",
    "if not found:\n",
    "    print(f\" Kevin Bacon (nm0000102) is NOT within 6 degrees of the top-rated comedy movie (tconst: {top_comedy_movie_tconst})\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 168549065520172,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Final_Project",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}